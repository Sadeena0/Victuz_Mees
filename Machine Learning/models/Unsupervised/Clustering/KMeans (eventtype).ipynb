{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from openpyxl.styles.builtins import total\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from feature_selectors import *\n",
    "\n",
    "# Suppress the specific warning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gebruikers_df = pd.read_csv(r'..\\..\\..\\data\\gebruikersinformatie.csv', delimiter = ';')\n",
    "evenement_df = pd.read_csv(r'..\\..\\..\\data\\evenementinformatie.csv', delimiter = ';')\n",
    "aanwezigheid_df = pd.read_csv(r'..\\..\\..\\data\\evenementaanwezigheid.csv', delimiter = ';')\n",
    "bericht_df = pd.read_csv(r'..\\..\\..\\data\\berichtinteracties_met_sentiment.csv', delimiter = ';')"
   ],
   "id": "9a50291f38823ab6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = merge_on_aanwezigheid(aanwezigheid_df, evenement_df, gebruikers_df)\n",
    "\n",
    "df"
   ],
   "id": "d84af57e11215256",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove nonvalid entries\n",
    "for col in df.columns:\n",
    "    df = df[~(df[col].isna())]\n",
    "\n",
    "df = df[~(df['Gebruiker_Lidmaatschapstype'] == 'x')]\n",
    "df"
   ],
   "id": "6ea60407f0c59e66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove alle id's\n",
    "to_remove = [\"EvenementID\", \"GebruikerID\", \"Evenement_OrganisatorID\"]\n",
    "df.drop(columns = to_remove, inplace = True)\n",
    "\n",
    "df"
   ],
   "id": "c41a94cca86a65fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "date_columns = ['Evenement_EvenementDatum', 'Gebruiker_RegistratieDatum', 'Gebruiker_LaatsteLogin']\n",
    "\n",
    "# DateTime columns\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], dayfirst = True)\n",
    "    \n",
    "    # # Days\n",
    "    # # Date since earliest date\n",
    "    # df[col] = (df[col] - df[col].min()).dt.total_seconds() / (24 * 3600)\n",
    "    # df[f'Long_ago_{col}'] = df[col] > df[col].mean()\n",
    "    # df[f'Recent_{col}'] = df[col] < df[col].mean()\n",
    "    \n",
    "    # Split on weekend/weekday\n",
    "    df[f'{col}_is_weekend'] = df[col].dt.weekday >= 5\n",
    "    \n",
    "    # # Months\n",
    "    # # Split on month number (change to name)\n",
    "    # df = pd.concat([df, pd.get_dummies(df[col].dt.month_name(), prefix = f'{col}_month')], axis = 1)\n",
    "    \n",
    "    # Split on seasons\n",
    "    df[f'{col}_is_spring'] = (df[col].dt.month >= 3) & (df[col].dt.month <= 5)\n",
    "    df[f'{col}_is_summer'] = (df[col].dt.month >= 6) & (df[col].dt.month <= 8)\n",
    "    df[f'{col}_is_autumn'] = (df[col].dt.month >= 9) & (df[col].dt.month <= 11)\n",
    "    df[f'{col}_is_winter'] = (df[col].dt.month >= 12) | (df[col].dt.month <= 2)\n",
    "    \n",
    "    df.drop(columns = col, inplace = True)\n",
    "\n",
    "df"
   ],
   "id": "d2b6ffce63cf7cdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dummies from studierichting\n",
    "df = pd.concat([df, pd.get_dummies(df['Gebruiker_Studierichting'], prefix = 'Gebruiker_Studierichting')], axis=1)\n",
    "df.drop(['Gebruiker_Studierichting'], axis = 1, inplace = True)\n",
    "\n",
    "# Factorize studiejaar with map\n",
    "df[\"Gebruiker_Studiejaar\"] = df[\"Gebruiker_Studiejaar\"].map({\n",
    "    \"eerstejaars\": 1,\n",
    "    \"tweedejaars\": 2,\n",
    "    \"derdejaars\": 3,\n",
    "    \"vierdejaars\": 4\n",
    "})\n",
    "\n",
    "# Object (string) columns\n",
    "for col in ['Aanwezigheidsstatus', 'Gebruiker_Lidmaatschapstype']:\n",
    "    df[col], unique_values = pd.factorize(df[col])\n",
    "\n",
    "    print(f\"\\n{col} numerics:\")\n",
    "    for i, value in enumerate(unique_values):\n",
    "        print(f\"{i} -> {value}\")\n",
    "        \n",
    "\n",
    "# Aanwezigheidsstatus (1 = aanwezig, 0 = afwezig)\n",
    "df['Aanwezigheidsstatus'] = ~df['Aanwezigheidsstatus'].replace(2, 1).astype('bool')\n",
    "\n",
    "df"
   ],
   "id": "b52dbe98a20b407e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Remove afwezige entries\n",
    "# df = df[~(df['Aanwezigheidsstatus'] == False)]\n",
    "# df"
   ],
   "id": "6dba4a4b1cbe8f71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define predictors (dimensions)\n",
    "predictor_df = pd.DataFrame(df).drop(columns = ['Evenement_EvenementType'])\n",
    "outcome_df = pd.DataFrame(df['Evenement_EvenementType'])"
   ],
   "id": "c266e80168fe22f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(predictor_df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns = predictor_df.columns)\n",
    "\n",
    "scaled_df"
   ],
   "id": "a1b66f8c5ac9b485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Only train on subset, keep test_x to make predictions and evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = scaled_df\n",
    "\n",
    "train_x, test_x = train_test_split(x, train_size = 0.85, shuffle = True, random_state = 0)\n",
    "\n",
    "train_x"
   ],
   "id": "418bc70b14842ba2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "states = 100\n",
    "max_n = 10 # Best N is afhankelijk van max_n? i am confusion\n",
    "best_n_frequency = {}\n",
    "\n",
    "# For each randomstate\n",
    "for state in range(states):\n",
    "    # Save score on each N\n",
    "    inertias = [KMeans(n_clusters = n, random_state = state).fit(train_x).inertia_ for n in range(1, max_n)]\n",
    "\n",
    "    # Determine N with best score\n",
    "    knee_locator = KneeLocator(range(1, max_n), inertias, curve = \"convex\", direction = \"decreasing\")\n",
    "    best_n = knee_locator.knee\n",
    "\n",
    "    if best_n is not None:\n",
    "        # Add a frequency point to that N\n",
    "        best_n_frequency[best_n] = best_n_frequency.get(best_n, 0) + 1\n",
    "\n",
    "# Determine most frequent best N\n",
    "most_frequent_best_n = max(best_n_frequency, key = best_n_frequency.get)\n",
    "\n",
    "# Plot results\n",
    "print(f'Most frequent best K: {most_frequent_best_n}')\n",
    "plt.bar(best_n_frequency.keys(), best_n_frequency.values())\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "id": "cb547e295e7d883c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train model one last time with most frequent best N\n",
    "kmeans = KMeans(n_clusters = most_frequent_best_n, random_state = 0).fit(train_x)"
   ],
   "id": "486f180522a655ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Showing distribution of cluster sizes\n",
    "unique_clusters, counts = np.unique(kmeans.labels_, return_counts = True)\n",
    "\n",
    "print(\"\\nCluster Size Distribution:\")\n",
    "for cluster, count in zip(unique_clusters, counts):\n",
    "    print(f\"Cluster {cluster}: {count} entries\")"
   ],
   "id": "920a97a0f5ba69a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Write clusters to entries\n",
    "train_x['Cluster'] = kmeans.labels_\n",
    "train_x = train_x.merge(outcome_df[['Evenement_EvenementType']], left_index = True, right_index = True, how = 'inner')\n",
    "train_x"
   ],
   "id": "7844b5aabfcf5600",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate total occurrences of each event type across all clusters\n",
    "filtered_outcome_df = outcome_df[outcome_df.index.isin(train_x.index)]\n",
    "total_event_counts = filtered_outcome_df['Evenement_EvenementType'].value_counts()\n",
    "\n",
    "# Calculate event type frequencies per cluster (as fractions)\n",
    "cluster_event_summary = (\n",
    "    train_x.groupby('Cluster')['Evenement_EvenementType']\n",
    "    .value_counts()\n",
    "    .unstack(fill_value = 0)  # Pivot to have event types as columns\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Normalize the frequencies by the total occurrences of each event type\n",
    "for event in ['bbq', 'lezing', 'hackathon', 'workshop']:\n",
    "    cluster_event_summary[event] = cluster_event_summary[event] / total_event_counts[event]\n",
    "\n",
    "# Rank events within each cluster\n",
    "cluster_event_summary['Event_Rankings'] = cluster_event_summary.loc[:, ['bbq', 'lezing', 'hackathon', 'workshop']].apply(\n",
    "    lambda row: row.sort_values(ascending = False).index.tolist(), axis = 1\n",
    ")\n",
    "\n",
    "print(total_event_counts)\n",
    "cluster_event_summary"
   ],
   "id": "d6af6b864a378545",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_list = []\n",
    "\n",
    "for i in range(0, test_x.shape[0]):\n",
    "    entry = test_x.iloc[[i]]\n",
    "    index = entry.index[0]\n",
    "\n",
    "    # Predict the cluster for the new entry\n",
    "    predicted_cluster = kmeans.predict(entry)[0]\n",
    "\n",
    "    # Retrieve event rankings for the predicted cluster\n",
    "    event_rankings = cluster_event_summary.loc[\n",
    "        cluster_event_summary[\"Cluster\"] == predicted_cluster, \"Event_Rankings\"\n",
    "    ].values\n",
    "\n",
    "    # Get actual event type of the entry\n",
    "    true_y = df.iloc[index]['Evenement_EvenementType']\n",
    "\n",
    "    results_list.append({\n",
    "        'Index': index,\n",
    "        'Cluster': predicted_cluster,\n",
    "        'Predicted': event_rankings[0],\n",
    "        'True': true_y,\n",
    "        'Correct': event_rankings[0][0] == true_y\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "results_df.set_index('Index', inplace = True)\n",
    "print(\n",
    "    f\"Correct predictions: {results_df['Correct'].sum()}\\t({(results_df['Correct'].sum() / results_df.shape[0]) * 100}%)\")\n",
    "\n",
    "results_df"
   ],
   "id": "4c760550817575d1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
